"""kaleido-scope - Generated by OpenScope"""

from typing import TYPE_CHECKING

import torch

from scope.core.pipelines.interface import Pipeline, Requirements
from scope.core.pipelines.base_schema import (
    BasePipelineConfig,
    ModeDefaults,
    UsageType,
    ui_field_config,
)

if TYPE_CHECKING:
    from scope.core.pipelines.base_schema import BasePipelineConfig


class KaleidoScopeConfig(BasePipelineConfig):
    """Configuration for the kaleido-scope pipeline.
    
    Main generative pipeline
    """
    
    pipeline_id = "kaleido-scope"
    pipeline_name = "Kaleido Scope"
    pipeline_description = "GPU kaleidoscope/mirror effect"
    supports_prompts = true
    usage = []
        modes = {"video": ModeDefaults(default=True)}


class KaleidoScopePipeline(Pipeline):
    """Pipeline generated from OpenScope node graph."""
    
    @classmethod
    def get_config_class(cls) -> type["BasePipelineConfig"]:
        return KaleidoScopeConfig

    def __init__(self, device: torch.device | None = None, **kwargs):
        self.device = device if device is not None else torch.device(
            "cuda" if torch.cuda.is_available() else "cpu"
        )

    def prepare(self, **kwargs) -> Requirements:
        return Requirements(input_size=1)

    def __call__(self, **kwargs) -> dict:
        video = kwargs.get("video")
        if video is None:
            raise ValueError("kaleido-scope requires video input")

        frames = torch.stack([f.squeeze(0) for f in video], dim=0)
        video = [frames[i] for i in range(frames.shape[0])]

    # No processing nodes - pass-through
    video = kwargs.get("video")
    if video is None:
        raise ValueError("Input video required")
    return {"video": torch.stack([f.squeeze(0) for f in video], dim=0) / 255.0}

        out = torch.stack(video, dim=0)
        return {"video": out.clamp(0, 1)}




def register_pipelines(register):
    """Hook to register this pipeline with Scope."""
    register(KaleidoScopePipeline)
